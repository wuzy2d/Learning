## Slicing Pandas DataFrame:
  df['egg']
  df['egg'][1:4]
  df.loc[:,'eggs':'salt']
  df.loc['Jan':'Apr',:]
  df.iloc[2:5,1:]
  df.loc['Jan':'May', [ 'eggs','spam']]
  df.iloc[[0,4,5],0:2]
  df.['eggs'] -- serie
  df.[['eggs']] -- dataframe

## Filtering Pandas DataFrame:
  df.salt > 60 -- Boolean
  df[df.salt > 60]
  df[Boolean] -- intuition
  df[ (df.salt>50) & (df.salt<60) ]
  df.loc [:, df.all() ] -- return columns with all non-zero values
  df.loc [:, df.any() ] -- return columns with any non-zero values
  df.loc [:, df.isnull().any() ] -- return columns with any NaN values
  df.loc [:, df.notnull().all()] -- return columns with all non-NaN values
  df.dropna (how='any') -- drop columns with any NaN
  df.eggs [ df.salt > 55 ] += 5
  
### Index objects and labeled data
  unemployment.index = unemployment['Zip']
  del unemployment['Zip']
  unemployment = pd.read_csv('Unemployment.csv',index='Zip')
  new_idx = [index.upper() for index in sales.index]
  sales.index = new_idx
  -- index is immutable, but can be replaced/changed all at once
  
### Hierarchical indexing
  stocks = stocks.set_index(['Symbol','Date']) -- set two columns to composite index
  stocks = stocks.sort_index()
  stocks.loc[('CSCO', ['2016','2017']), :]
  stocks.loc[(slice(None),slice('2016','2017)), :] -- range operation
  
### Pivoting DataFrames
  trials.pivot(index='treatment',columns='gender') -- retain all values
  trials.pivot(index='treatment',columns='gender',value='response') -- specify value
  
### Stacking & unstacking DataFrames
  -- pivot doesn't work with multi-level indexes
  trials.unstack(level=1) -- to remove level 1 index and turn into column
  trials.unstack(level='gender')
  trials.stack(level='gender')
  swapped = stacked.swaplevel(0, 1) -- swaping index levels
  swapped.sort_index()
  
### Melting DataFrames
  pd.melt(new_trials,id_vars=['treatment']),value_vars=['F','M'])
  
### Pivot tables
  more_trials.pivot_table(index='treatment',columns='gender',values='response',aggfunc='count')
  
### Categoricals and groupby
  sales.groupby('weekday')['bread'].sum()
  sales.grouby(['city','weekday']).mean()
  sales['weekday'] = sales['weekday'].astype('category') -- convert string to category, less memory, faster groupby
  sales.groupby('city')[['bread','butter']]agg(['max','sum']) -- two aggregations, resulting multi level index in columns
  def data_range(series):
    return series.max()-series.min()
  sales.groupby('weekday').['bread'].agg(data_range)
  sales.groupby(customers)[['bread','butter']].agg({'bread':'sum','butter':data_range})
  
### Groupby and transformation
  def zscore(series):
    return (series-series.mean())/series.std()
  zscore(auto['mpg']).head()
  auto.groupby('yr')['mpg'].transform(zscore).head()
  def zscore_with_year_and_name(group):
    df = pd.DataFrame(
            {'mpg':zscore(group['mpg']),
             'year':group['yr'],
             'name':group['name']})
    return df
  auto.groupby('yr').apply(zscore_with_year_and_name).head()
  
### Groupby and filtering
  splitting = auto.groupby('yr')
  for group_name, group in splitting:
    avg = group['mpg'].mean()
    print(group_name, avg)
  for group_name, group in splitting:
    avg = group.loc[group['name'].str.contains('cherolet'),'mpg'].mean()
    print(group_name,avg)
  chevy_mean = {year:group.loc[group['name'].str.contains('chevrolet'),'mpg'].mean()
                  for year,group in splitting}
  pd.Series(chevy_means)
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
